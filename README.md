# Project -1 : Linear Regression with Iris Dataset (MLflow Tracking) 

## ğŸ“Œ Project Status
ğŸš§ **Work in Progress**  
This project is under active development. Core setup and MLflow integration are completed, while model improvements and evaluation are still ongoing.

---

## ğŸ“– Project Overview
This repository demonstrates a **Linear Regression model** built using the **Iris dataset**, with experiment tracking and model inference managed through **MLflow**.

The project focuses on:
- Setting up a clean Python development environment
- Training a regression model on the Iris dataset
- Tracking experiments using MLflow
- Logging and inferencing model artifacts with MLflow
- Inferencing model Artigacts with MLFLOW inferncing, Tracking parameters
- Comparing Diff models vs metrics
- Validate tyhe model before deployment via Inferencing,
- And load model back prediction as Generative python function (MLFLOW.pyfunc)
- Register model in MLFLOW: version, tags, and Aliase
- Inferencing from model registry: Model, parameters, ,model_uri path, prediction values

---

## ğŸ› ï¸ Technologies Used
- Python
- Scikit-learn
- Pandas
- NumPy
- MLflow
- VS Code
- Virtual Environment (`venv`)

---

## Project -2 :   House Price Prediction with MLflow Tracking 

## ğŸ“Œ Project Overview 
This project demonstrates an **end-to-end machine learning workflow** for **house price prediction** using the **California Housing dataset** and **MLflow** for experiment tracking, hyperparameter tuning, and model registration.

The main goals of this project are: 
- Train a regression model with hyperparameter tuning 
- Track all experiments, parameters, and metrics using MLflow
- Compare multiple runs in the MLflow UI 
- Register the best-performing model in the MLflow Model Registry 

--- 

## ğŸ“Š Dataset 
- **California Housing Dataset** 
- Source: `sklearn.datasets.fetch_california_housing` 
- Number of samples: **20,640**
- Features:  - MedInc (Median Income),  - HouseAge, - AveRooms, - AveBedrms 
  - Population, - AveOccup, - Latitude, - Longitude 
- Target: 
  - **Price** (Median house value in units of $100,000) 

---
## ğŸ§  Model 
- Algorithm: **Random Forest Regressor** 
- Evaluation metric: **Mean Squared Error (MSE)** 
- Hyperparameter tuning: **GridSearchCV** 

---

## âœ… Project Workflow 

### 1ï¸âƒ£ Data Loading 
- Dataset loaded using `fetch_california_housing` 
- Converted into a pandas DataFrame 
- Target variable added as `Price` 

---

### 2ï¸âƒ£ Data Preparation 
- Independent variables (`X`) created by dropping the `Price` column 
- Dependent variable (`y`) set as `Price` 
- Train-test split performed (80% training / 20% testing) 

---

### 3ï¸âƒ£ Hyperparameter Tuning 
- Hyperparameter tuning implemented using `GridSearchCV` 
- Parameters tuned: 
  - `n_estimators` , - `max_depth` , - `min_samples_split`, - `min_samples_leaf`, - 3-fold cross-validation used 
- Scoring metric: `neg_mean_squared_error` 

---

### 4ï¸âƒ£ Model Training & Evaluation 
- Best model selected from GridSearchCV 
- Predictions generated on test data 
- Mean Squared Error calculated 

---

### 5ï¸âƒ£ MLflow Experiment Tracking 
- MLflow tracking server used (`http://127.0.0.1:5000`) 
- Logged to MLflow: Best hyperparameters, Mean Squared Error (MSE), Model artifacts  
- Model input/output signature inferred using `infer_signature` 

---

### 6ï¸âƒ£ Model Registration 
- Best-performing model registered in **MLflow Model Registry** 
- Registered model name:


### Best Model: Random Forest Regressor 
    Best Hyperparameters: 
    n_estimators: 200 
    max_depth: None 
    min_samples_split: 2 
    min_samples_leaf: 1 
    Mean Squared Error (MSE): ~0.25 
    Model successfully tracked and registered in MLflow 
---

# Project -3 ANN with MLflow â€“ Endâ€‘toâ€‘End MLOps Project

## ğŸ” Project Summary
Production-oriented **MLOps pipeline** demonstrating how to train, tune, track, register, and serve an **Artificial Neural Network (ANN)** using **MLflow**.  
The project covers the **full ML lifecycle** from experimentation to deployment-ready inference.

---

## ğŸ’¼ Why This Project Matters  
This project demonstrates hands-on experience with:
- âœ… **Experiment tracking at scale**
- âœ… **Hyperparameter optimization**
- âœ… **Model registry & versioning**
- âœ… **Reproducible ML workflows**
- âœ… **Deployment-ready model artifacts**

It reflects **real-world ML engineering and MLOps practices**, not just model training.

---

## ğŸ§  Technical Highlights

### Model
- ANN built with **Keras**
- Regression task (Wine Quality prediction)
- Feature normalization inside the model graph
- Metric-driven model selection (RMSE)

### Optimization
- **Hyperopt + TPE** for hyperparameter search
- Search space:
  - Learning rate (log-uniform)
  - Momentum (uniform)
- Best model selected automatically based on validation RMSE

---

## ğŸ§ª Experiment Tracking & Model Management
- **MLflow Experiments**
  - Parameters
  - Metrics
  - Model artifacts
- **Nested runs** for hyperparameter sweeps
- **MLflow Model Registry**
  - Versioned models
  - Promotion-ready artifacts

---

## ğŸš€ Inference & Serving Readiness
- Model loaded using **MLflow PyFunc**
- Serving input validated prior to deployment
- Compatible with:
  - REST API serving
  - Batch inference
  - Cloud ML platforms

---

## â˜ï¸ Deployment Readiness
- MLflow-compatible model format
- Can be packaged into:
  - Docker containers
  - Cloud-native serving endpoints
- Clear separation of training, evaluation, and inference

---

## ğŸ›  Tech Stack
- Python 3.10
- Keras / TensorFlow
- MLflow
- Hyperopt
- Scikit-learn
- Pandas / NumPy

---

## ğŸ“Š Key Outcomes
- Automated experiment comparison
- Best-performing ANN selected and registered
- Fully reproducible ML pipeline
- Production-aligned workflow (training â†’ registry â†’ inference)

---

## ğŸ¯ Skills Demonstrated
- MLOps & ML Engineering
- Experiment tracking & reproducibility
- Hyperparameter optimization
- Model versioning & governance
- Deployment-oriented ML design

---
# Project -4:  Machine Learning Pipeline with DVC & MLflow
ğŸ“Œ Project Overview

This project demonstrates how to build an end-to-end machine learning pipeline using DVC (Data Version Control) for data and model versioning and MLflow for experiment tracking.
The pipeline trains and evaluates a Random Forest Classifier on the Pima Indians Diabetes Dataset, following best practices for reproducibility and MLOps.

The goal of this project is to show how data, code, models, and experiments can be tracked together in a structured and scalable way. (dagshub.com)
ğŸš€ Key Features

    âœ… End-to-end ML pipeline
    âœ… Data and model versioning with DVC
    âœ… Experiment tracking with MLflow
    âœ… Reproducible pipeline stages
    âœ… Modular and scalable project structure
    âœ… Integration-ready with cloud storage (S3 / GCS / Azure)

ğŸ§° Tech Stack

    Python
    Scikit-learn
    DVC â€“ data & pipeline versioning
    MLflow â€“ experiment tracking
    Git / DagsHub â€“ code, data, and collaboration

ğŸ“‚ Project Structure
text

machinelearningpipeline/
â”‚
â”œâ”€â”€ data/                  # Raw and processed datasets (DVC tracked)
â”œâ”€â”€ src/                   # Source code for pipeline stages
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ evaluate_model.py
â”‚
â”œâ”€â”€ models/                # Trained models (DVC tracked)
â”œâ”€â”€ dvc.yaml               # DVC pipeline definition
â”œâ”€â”€ params.yaml            # Model and pipeline parameters
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation

ğŸ”„ Pipeline Stages

    Data Preprocessing
        Cleans and prepares the dataset
        Splits data into training and test sets

    Model Training
        Trains a Random Forest Classifier
        Logs parameters and metrics to MLflow

    Model Evaluation
        Evaluates model performance
        Tracks evaluation metrics for comparison

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Clone the Repository
bash

git clone https://dagshub.com/venky.sarangi/machinelearningpipeline
cd machinelearningpipeline

2ï¸âƒ£ Create Environment & Install Dependencies
bash

pip install -r requirements.txt

3ï¸âƒ£ Run the DVC Pipeline
bash

dvc repro

ğŸ“Š Experiment Tracking

All experiments, metrics, and model artifacts are logged using MLflow.
You can compare runs and analyze performance directly from the DagsHub UI.
â˜ï¸ Data & Model Versioning

    Datasets and models are tracked using DVC
    Supports remote storage (AWS S3, GCS, Azure, or DagsHub Storage)
    Ensures full reproducibility across environments

ğŸ¯ Use Cases

    Learning MLOps fundamentals
    Building reproducible ML workflows
    Experiment tracking and model comparison
    Production-ready ML pipeline templates

ğŸ¤ Contributing

Contributions are welcome!
Feel free to open issues or submit pull requests to improve the pipeline.
ğŸ“œ License

This project is intended for educational and learning purposes.
â­ If you find this project useful, consider starring it!

If you want, I can also:

    Tailor this README for GitHub vs DagsHub
    Add badges (Python, DVC, MLflow)
    Create a Beginner-friendly version
    Generate a project architecture diagram


# Project -5  ğŸ³ Basic Hello Docker Project 

- `docker --version` â†’ Verify Docker installation  
- `docker build -t welcome-app .` â†’ Build Docker image  
- `docker run -p 5000:5000 welcome-app` â†’ Run the container  
- `docker ps` â†’ Check running containers


# Project -6.1 ğŸš€ Apache Airflow Learning Projects (Math + MLOps)

This repository contains beginnerâ€‘toâ€‘intermediate Apache Airflow examples designed to help you understand realâ€‘world workflows and MLOps pipelines using modern Airflow 2.x (TaskFlow API).

âœ… Can be run locally using Astronomer (Astro CLI)
âœ… Easy to understand and productionâ€‘oriented
âœ… Fully compatible with Airflow UI
ğŸ“‚ Project Structure
text

.
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ math_sequence_dag.py
â”‚   â””â”€â”€ mlops_basic_pipeline.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ“Œ Project 1: Math Sequence DAG
ğŸ”¢ Description

This DAG demonstrates task dependencies and XCom value passing using a simple math workflow.
âœ… Workflow Steps

    Start with number 10
    Add 5
    Multiply by 2
    Subtract 3
    Square the final result

âœ… Concepts Learned

    DAG creation
    TaskFlow API (@task)
    Task dependencies
    Automatic XComs
    Logs in Airflow UI

âœ… Final Result
basic

10 â†’ 15 â†’ 30 â†’ 27 â†’ 729

ğŸ“„ DAG File

dags/math_sequence_dag.py

# Project -6.2: Realâ€‘World MLOps Pipeline
ğŸ¤– Description

This project simulates a productionâ€‘style MLOps workflow commonly used in real companies.
âœ… Workflow Steps

    Extract data (mock)
    Validate data
    Train ML model
    Evaluate model performance
    Decide whether to deploy

âœ… Concepts Learned

    Endâ€‘toâ€‘end ML pipelines
    Data validation
    Model training & evaluation
    Deployment decision logic
    Failure handling

ğŸ“„ DAG File

dags/mlops_basic_pipeline.py

ğŸ”„ MLOps Workflow Diagram (Logical)

Extract Data
     â†“
Validate Data
     â†“
Train Model
     â†“
Evaluate Model
     â†“
Deploy Model (Yes / No)

ğŸ› ï¸ Prerequisites

    Docker
    Git
    Astro CLI

âœ… Install Astro CLI
bash

curl -sSL https://install.astronomer.io | sudo bash

Verify:
bash

astro version

â–¶ï¸ How to Run the Project Locally
1ï¸âƒ£ Clone the Repository
bash

git clone https://github.com/your-username/airflow-learning-projects.git
cd airflow-learning-projects

2ï¸âƒ£ Start Airflow with Astro
bash

astro dev start

3ï¸âƒ£ Open Airflow UI

http://localhost:8080

Login:

Username: admin
Password: admin

4ï¸âƒ£ Trigger the DAGs

    math_sequence_dag
    mlops_basic_pipeline

ğŸ¯ What You Will Learn
âœ… Apache Airflow

    DAG lifecycle
    TaskFlow API
    Scheduling
    Logging & retries
    XComs
    UI debugging

âœ… MLOps Foundations

    Pipeline design
    Model validation
    Deployment decision logic
    Productionâ€‘style workflows

ğŸ§  How This Maps to Real Production Systems
Learning Example	Real Production
extract_data	S3 / BigQuery / APIs
validate_data	Great Expectations
train_model	sklearn / PyTorch
evaluate_model	MLflow
deploy_model	Kubernetes / SageMaker
ğŸš€ Future Enhancements

Planned improvements:

    MLflow integration
    Branching DAGs
    Sensors for new data
    CI/CD for DAGs
    Feature engineering pipelines
    Retraining schedules

ğŸ¤ Contributions

Contributions are welcome!
Feel free to:

    Open issues
    Submit pull requests
    Suggest improvements

ğŸ“œ License

This project is licensed under the MIT License.
â­ Support

If this repository helped you learn Airflow or MLOps:

    â­ Star the repo
    ğŸ” Share it with others

Happy Learning & Orchestrating ğŸš€
