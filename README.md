# Project -1 : Linear Regression with Iris Dataset (MLflow Tracking) 

## ğŸ“Œ Project Status
ğŸš§ **Work in Progress**  
This project is under active development. Core setup and MLflow integration are completed, while model improvements and evaluation are still ongoing.

---

## ğŸ“– Project Overview
This repository demonstrates a **Linear Regression model** built using the **Iris dataset**, with experiment tracking and model inference managed through **MLflow**.

The project focuses on:
- Setting up a clean Python development environment
- Training a regression model on the Iris dataset
- Tracking experiments using MLflow
- Logging and inferencing model artifacts with MLflow
- Inferencing model Artigacts with MLFLOW inferncing, Tracking parameters
- Comparing Diff models vs metrics
- Validate tyhe model before deployment via Inferencing,
- And load model back prediction as Generative python function (MLFLOW.pyfunc)
- Register model in MLFLOW: version, tags, and Aliase
- Inferencing from model registry: Model, parameters, ,model_uri path, prediction values

---

## ğŸ› ï¸ Technologies Used
- Python
- Scikit-learn
- Pandas
- NumPy
- MLflow
- VS Code
- Virtual Environment (`venv`)

---

## Project -2 :   House Price Prediction with MLflow Tracking 

## ğŸ“Œ Project Overview 
This project demonstrates an **end-to-end machine learning workflow** for **house price prediction** using the **California Housing dataset** and **MLflow** for experiment tracking, hyperparameter tuning, and model registration.

The main goals of this project are: 
- Train a regression model with hyperparameter tuning 
- Track all experiments, parameters, and metrics using MLflow
- Compare multiple runs in the MLflow UI 
- Register the best-performing model in the MLflow Model Registry 

--- 

## ğŸ“Š Dataset 
- **California Housing Dataset** 
- Source: `sklearn.datasets.fetch_california_housing` 
- Number of samples: **20,640**
- Features:  - MedInc (Median Income),  - HouseAge, - AveRooms, - AveBedrms 
  - Population, - AveOccup, - Latitude, - Longitude 
- Target: 
  - **Price** (Median house value in units of $100,000) 

---
## ğŸ§  Model 
- Algorithm: **Random Forest Regressor** 
- Evaluation metric: **Mean Squared Error (MSE)** 
- Hyperparameter tuning: **GridSearchCV** 

---

## âœ… Project Workflow 

### 1ï¸âƒ£ Data Loading 
- Dataset loaded using `fetch_california_housing` 
- Converted into a pandas DataFrame 
- Target variable added as `Price` 

---

### 2ï¸âƒ£ Data Preparation 
- Independent variables (`X`) created by dropping the `Price` column 
- Dependent variable (`y`) set as `Price` 
- Train-test split performed (80% training / 20% testing) 

---

### 3ï¸âƒ£ Hyperparameter Tuning 
- Hyperparameter tuning implemented using `GridSearchCV` 
- Parameters tuned: 
  - `n_estimators` , - `max_depth` , - `min_samples_split`, - `min_samples_leaf`, - 3-fold cross-validation used 
- Scoring metric: `neg_mean_squared_error` 

---

### 4ï¸âƒ£ Model Training & Evaluation 
- Best model selected from GridSearchCV 
- Predictions generated on test data 
- Mean Squared Error calculated 

---

### 5ï¸âƒ£ MLflow Experiment Tracking 
- MLflow tracking server used (`http://127.0.0.1:5000`) 
- Logged to MLflow: Best hyperparameters, Mean Squared Error (MSE), Model artifacts  
- Model input/output signature inferred using `infer_signature` 

---

### 6ï¸âƒ£ Model Registration 
- Best-performing model registered in **MLflow Model Registry** 
- Registered model name:


### Best Model: Random Forest Regressor 
    Best Hyperparameters: 
    n_estimators: 200 
    max_depth: None 
    min_samples_split: 2 
    min_samples_leaf: 1 
    Mean Squared Error (MSE): ~0.25 
    Model successfully tracked and registered in MLflow 
---

# Project -3 ANN with MLflow â€“ Endâ€‘toâ€‘End MLOps Project

## ğŸ” Project Summary
Production-oriented **MLOps pipeline** demonstrating how to train, tune, track, register, and serve an **Artificial Neural Network (ANN)** using **MLflow**.  
The project covers the **full ML lifecycle** from experimentation to deployment-ready inference.

---

## ğŸ’¼ Why This Project Matters  
This project demonstrates hands-on experience with:
- âœ… **Experiment tracking at scale**
- âœ… **Hyperparameter optimization**
- âœ… **Model registry & versioning**
- âœ… **Reproducible ML workflows**
- âœ… **Deployment-ready model artifacts**

It reflects **real-world ML engineering and MLOps practices**, not just model training.

---

## ğŸ§  Technical Highlights

### Model
- ANN built with **Keras**
- Regression task (Wine Quality prediction)
- Feature normalization inside the model graph
- Metric-driven model selection (RMSE)

### Optimization
- **Hyperopt + TPE** for hyperparameter search
- Search space:
  - Learning rate (log-uniform)
  - Momentum (uniform)
- Best model selected automatically based on validation RMSE

---

## ğŸ§ª Experiment Tracking & Model Management
- **MLflow Experiments**
  - Parameters
  - Metrics
  - Model artifacts
- **Nested runs** for hyperparameter sweeps
- **MLflow Model Registry**
  - Versioned models
  - Promotion-ready artifacts

---

## ğŸš€ Inference & Serving Readiness
- Model loaded using **MLflow PyFunc**
- Serving input validated prior to deployment
- Compatible with:
  - REST API serving
  - Batch inference
  - Cloud ML platforms

---

## â˜ï¸ Deployment Readiness
- MLflow-compatible model format
- Can be packaged into:
  - Docker containers
  - Cloud-native serving endpoints
- Clear separation of training, evaluation, and inference

---

## ğŸ›  Tech Stack
- Python 3.10
- Keras / TensorFlow
- MLflow
- Hyperopt
- Scikit-learn
- Pandas / NumPy

---

## ğŸ“Š Key Outcomes
- Automated experiment comparison
- Best-performing ANN selected and registered
- Fully reproducible ML pipeline
- Production-aligned workflow (training â†’ registry â†’ inference)

---

## ğŸ¯ Skills Demonstrated
- MLOps & ML Engineering
- Experiment tracking & reproducibility
- Hyperparameter optimization
- Model versioning & governance
- Deployment-oriented ML design

---
